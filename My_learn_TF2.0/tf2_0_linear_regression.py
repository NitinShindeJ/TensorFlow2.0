# -*- coding: utf-8 -*-
"""TF2.0 Linear Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bdrnXPEXv9ETfEV0z3vpY55DFvkJn9Oy
"""

#Install Tensor flow
!pip install -q tensorflow==2.0.beta1

import tensorflow as tf
#print(tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#Get the data from gitHub
!wget https://github.com/NitinShindeJ/TensorFlow2.0/tree/master/tf2.0/moore.csv

#Load the data
df = pd.read_csv('moore.csv', header=None, error_bad_lines=False).values

X=df[:,0].reshape(-1,1) #make it 2D array of size NxD where D=1
Y=df[:,1]



df

#Load the data
df = pd.read_csv('moore_1.csv', header=None, error_bad_lines=False).values

import re

X = []
Y = []

# some numbers show up as 1,170,000,000 (commas)
# some numbers have references in square brackets after them
non_decimal = re.compile(r'[^\d]+')

for line in open('moore_1.csv'):
    r = line.split('\t')

    x = int(non_decimal.sub('', r[2].split('[')[0]))
    y = int(non_decimal.sub('', r[1].split('[')[0]))
    X.append(x)
    Y.append(y)


X = np.array(X)
Y = np.array(Y)

#Plot the data
plt.scatter(X, Y);

#So we want  linear model take log
Y= np.log(Y) 
plt.scatter(X,Y);

#Pre processing X
# center X, X is the year so large range values, 
X=X-X.mean()

#Now we create TensorFlow
model = tf.keras.models.Sequential([
                                    tf.keras.layers.Input(shape=(1,)),
                                    tf.keras.layers.Dense(1)])

model.compile(optimizer=tf.keras.optimizers.SGD(0.001, 0.9), loss='mse')
#model.compile(Optimizer='adam', loss='mse')

#learning rate scheduler
def schedule(epoch, lr):
  if epoch >= 50:
    return 0.0001
  return 0.001

scheduler = tf.keras.callbacks.LearningRateScheduler(schedule)

#Train the model
r = model.fit(X, Y, epochs=200, callbacks=[scheduler])

#Plot the loss
plt.plot(r.history['loss'], label='loss')

#Get the slope of the line
#Slope of the line is related to the doubling rate of transistor count
print(model.layers) #Note: there is only 1 layer, the 'Input' layer doesn't count
print(model.layers[0].get_weights())

#Slope of the line is
a = model.layers[0].get_weights()[0][0,0]

a

print('Time to Double:', np.log(2)/a)

#If You want Analytical Soln
X = np.array(X).flatten()
Y=np.array(Y)
denominator = X.dot(X)-X.mean()*X.sum()
a = (X.dot(Y)-Y.mean()*X.sum()) / denominator
b = (Y.mean()*X.dot(X)-X.mean()*X.dot(Y))/denominator

print(a,b)
print('Time to Double:', np.log(2)/a)

"""# **Making Prediction**"""

#Make Sure the line fits our data
Yhat = model.predict(X).flatten()
plt.scatter(X, Y)
plt.plot(X, Yhat);

#Manual Cal

#Get the weights
w, b = model.layers[0].get_weights()

#Reshape X because we flattened it again earlier
X = X.reshape(-1, 1)

# (N*1) * (1*1) + (1) --> (N*1)
Yhat2 = (X.dot(w) + b).flatten()

#Don't use == for floting points
np.allclose (Yhat, Yhat2)